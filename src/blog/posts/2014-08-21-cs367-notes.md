---
layout: post.pug
title: CompSci 367 notes
category: uni
excerpt: Artificial Intelligence
---

#### Logic
- __Entail__ - _KB |= a_ if and only if _a_ is true in all worlds were KB is true
- __Infer__ - _KB |- i a_ = sentence _a_ can be derived from _KB_ by algorithm _i_
	- _i_ is __sound__ if whenever we infer something from _i_ it is also entailed by the KB
	- _i_ is __complete__ if something is entailed by the KB, then _i_ infers it
- __Conjunctive normal form__ (CNF): conjunction of disjunction of literals e.g. _(A or B) and (B or C)_
- __Negation__ in prolog, when something cannot be proved true it is _false_

#### Search
- __Complete__ - always finds a solution if one exists
- __Optimal__ - finds the _best_ solution
- _b_ - branching factor
- _d_ - depth of least cost solution
- _m_ - maximum depth of state space
- _f(n)_ is the _desirability_ of node _n_
- _g(n)_ is the cost from _initialState_ to _n_
- _h(n)_ is the estimate of the distance from _n_ to _goal_
	- __Admissible__ if the estimate is less than the actual cost (i.e. never overestimates)
	- __Consistent__ if obeys the triangle inequality (i.e. _h(n)_ is <= the cost from _n_ to _n'_ + _h(n')_)
	- a heuristic is likely to be better when its _average h-value_ (_r_) is higher
		-  __dominates__ another heuristic when _h1(n) > h2(n)_ for ALL _n_
	- uninformed tree = _b^d_, informed = _b^(d-r)_
	- heuristic can be formed from a __relaxed problem__ (reduce the restrictions)

| | Complete? | Time | Space | Optimal | _f(n)_ | Notes.. |
|:---|:---:|:---:|:---:|:---:|:---:|:---|
| BFS | Y (if _b_ finite) | Exponential | Exponential | Y (if step costs = 1) | | Uses a tonne of space (Graph search) |
| DFS | N (loops/infinite _m_) | Exponential | Linear (only keeps best in mem) | N | | |
| ID DFS | Y | Exponential | Linear (discard after each step) | Y (if step costs = 1) | | DFS + BFS advantages |
| Greedy | N | Exponential | Exponential | N | _h(n)_ | Doesn't care about _g(n)_ |
| A* | Y | Exponential | Exponential | Y (if _h_ is admissible + consistent) | _g(n) + h(n)_ | |
| IDA* | Y | Exponential | Linear | Y | _g(n) + h(n)_ | Iterates on the _f-limit_ - start with _h(init)_ |
| Weighted A* | Y | Exponential | Exponential | Y | _g(n) + h(n) * w_ | will be no worse than _w_ times as costly as optimal |
| Bidirectional A* Front-to-Back | Y | Exponential | Exponentially smaller (_b^(d/2)_) | Y | _g(n) + h(n)_ | _h(n)_ estimates diastase to the opposite terminal (init or goal), keeps searching for optimal |
| Bidirectional A* Front-to-Front | Y | Exponential | Exponentially smaller (_b^(d/2)_) | Y | _g(n) + h(n)_ | _h(n)_ estimates diastase to the opposite frontier, optimal on first collision!, cost of computing _h_ grow exponentially |
| Min-Max | Y | Exponential | Linear | Y (against optimal opponent) | _minmax value_ | |
| Min-Max _a-b_ pruning | Y | Exponentially smaller (_b^(m/2)_) | Linear | .. | _minmax value_ | _doubles_ depth which can be done in the same time |

- __Monte Carlo Tree Search__ plays out the rest of a game randomly, thousands of times, picks the one with the highest win rate. (explores the whole problem space)

#### Local Search
- __Hill climbing__ algorithm
	- always moves toward a maxima - can get stuck on a local maxima, missing the global maximum
	- add _random-restarts_ when you get stuck - trivially complete (depends on the shape of the state-space landscape)
- __Simulated annealing__ search - allows some 'bad' moves to escape local maxima, but _gradually decreases_ their size and frequency
- __Local beam__ search
	- start with _k_ randomly generated states
	- better than random restarts as information is shared -- but can get concentrated in a small region
- __Stochastic beam__ search - choose _k_ successors randomly, biased towards good ones (natural selection)

#### Genetic algorithms
- requires: reproduction, population, variety, difference in ability to survive
- reproduce with a _probability proportional to their fitness_
- __overcrowding__ can happen if one individual is too dominant


#### Constraint satisfaction problems (CSP)
- _state_ is defined by __variables__ _Xi_ with _values_ from __domain__ _Di_
- _goal test_ is a set of __constraints__ specifying allowable combinations of values for subsets of variables
	- __Unary__ constraints involve a single variable (_X != 5_)
	- __Binary__ constraints involve variable pairs (_X != Y_)
	- __Higher-order__ 3 or more variables
- __Incremental search__ - assign values to variables that do not conflict with current assignment
- __Backtracking__ search (DFS)
	- choose the most constrained variable i.e. with the fewest legal values (_minimum remaining values (MRV)_ heuristic)
	- __Forward checking__ - keep track of legal values for all variables, abort when a variable has none remaining
	- __Arc consistency__ - also keeps track of the affect that forward checking has on neighbours (detects failure earlier)	



----
## Week 6 - 12

#### Decision making & choice
- The __choice task__:
	- Given: some _goals/objectives_; _candidates relevant to these aims_; _descriptions_ for each
	- _Find_: one or more candidates to _select/carry out_
- __Decision theory__ (_prescriptive_)
	- Given: _K_ alternatives; _N_ attribute values; _N_ weights (_importance_)
	- _Compute_: the _utility value_ of each alternative == _UJ_ = sum of each (weight x value)
- __Heuristic choice__ (_descriptive_)
	- humans do _not make optimal choices_ but instead __satisfice__ (i.e., use heuristics to select an __acceptable__ alternative based on an __aspiration level__ with __minimal effort__)
	- humans retrieve _chunks_ of relevant memory (by __pattern matching__) to produce associated responses very rapidly
	- AI defines two forms of heuristics:
		- __Symbolic heuristics__ -- rules or relational patterns (as in human cognition, _chunks_ -- used in heuristic choice theory)
		- __Numeric heuristics__ -- arithmetic combinations of attributes (similar to utility functions -- used to find optimal choices and in search)

#### Reactive control for routine behaviour
- _sequential decision making_ by invoking the basic process repeatedly --> __reactive control__ task
	- Given: description of _environment_; related _goals_ [+ _beliefs_, or _mental states_]
	- _Select_: an appropriate _action_ to execute
- routine control is _conditional_, which gives it great flexibility. this can be done by direct mappings from perception to action -- known as __stimulus-response__ (does not take advantage of mental states)
- in reality, humans draw _inferences_ about current situation, have _memories_ of past decisions, knowledge of _order_ of activities, breakdown activities to _subactivities_, take _goals_ into account -- extensions can attempt to address these issues, but the stimulus-response paradigm has inherent limitations

#### HTNs
- __hierarchical structures__: +each component is _simple_, +_modular_ +_reusable_ +_composable_ dynamically
- comprise of a set of _methods_ with: a _task predicate_; _conditions_ under which the method applies; _subtasks_ that make up the method; [_effects_ the method produces]
- imposes a _hierarchical_, _sequential_, _conditional_ structure on activities
- this produces an _AND/OR tree_ which is transversed over time -- this _reactive_, but continues along the current path when possible
- __executing HTNs__ given some task _T_, on each cycle:
	1. infer a set of beliefs from stimuli (using conceptual rules)
	2. find (through the hierarchy) a _path_ of applicable methods
	3. execute

#### Production systems
- can model _human cognition_ -- support mental activities; combine _parallel retrieval_ with _sequential decisions_; balance _stimulus-driven_ and _goal-driven_ behaviour; _modular representation_ supports structural learning
- made up of 2 main components:
	- __Production memory__ containing generalized _rules_ that specify domain knowledge as conditional responses -- _condition-action_ form
	- __Working memory__ that contains specific _elements_
		- internal stimuli -- encoding the systems beliefs and goals
		- changes as the program runs
- runs __recognize-act cycles__
	1. match each rules conditions with working memory
	2. select one (or more) of the matched rules to execute
		- __conflict resolution__ can be: match more recent elements, match more specific sets, more conditions, rules added earlier
	3. execute

#### Causal models + Qualitative reasoning
- __Causal prediction/simulation__ task:
	- Given: _entities_ & _attributes_; _relations/rules_ that relate them; _external influences_
	- _Find_: the _resulting effects_ on attributes of interest
- this makes a _mental model_ -- analogous to a physical model
- definition: _X_ __causally influences__ _Y_ if a change in _X_'s value results in a change in _Y_'s value (provided everything else constant)
- this does _not_ infer _causality_ 
- e.g. `oil_production  --gas_price  --traffic  ++pollution  ++lung_disease`
- use a qualitative but dynamic causal model to generate __Qualitative Envisionments__
	- include: initial qualitative state, set of possible qualitative _successor states_, set of _transitions_
	- envisionment encodes the set of _possible_ trajectories
	- _nondeterministic_ because they abstract details
	- -multiple influences can cause weak predictions, -difficult to visualize and interpret

#### Explanations
- __explanation generation__ task:
	- Given: set of general _knowledge elements_; set of _observed facts_
	- _Find_: one (or more) _explanation_ that relate the observations (_connected_ to others through general _knowledge_)
- _understand_ often means explained
- we can use causal relations to create a _deductive causal explanation_ (e.g. oil production leads to +lung disease)

#### Abductive reasoning
- __abductive inference__ task:
	- Given: general rules/knowledge; specific _observed facts_
	- _Find_: one (or more) explanation that relate observations and _plausible assumptions_
		- observed facts + specific default __assumptions__ + _rule instances_ that link facts and assumptions
- key difference: the creation of __default assumptions__ that complete the account
- take the form of _proof trees_, but the assumptions are _not_ deductively valid
- inference to the best explanation? too concerned with optimality -- humans often arrive at incomplete/incorrect explanations through abduction
- e.g. __abductive explanation__

```prolog
%% background knowledge
good_mood(X) :- did_well_on(X,Y).
did_well_on(X,Y) :- exam(Y), study(X,Y), take(X,Y).

%% suppose we observe
good_mood(john).	exam(e).	take(john,e).

%% suppose we want to explain why john is in a good mood
%% if we make one assumption:
study(john,e).

%% we could derive good_mood(john) from this assumption and the observations
good_mood(john) :- /** observation to explain **/ 
	did_well_on(john,e) :- 
		exam(e),
		study(john,e), /** assumption **/
		take(john,e).
```

- _prefer_: +simpler explanations; +more probable accounts; +minimum weight assumptions; +_coherent_ explanations (those which _relate more observations_)

#### Case-based and Analogical reasoning
- humans are able to take advantage of background knowledge from specific experiences stored in memory (when general rules are unknown/unavailable)
- operates using 4 main stages:
	1. input some query or problem;
	2. retrieve relevant cases from memory;
		- typically based on _similarity_ between the case and query/problem
	3. select which case(s) to utilize; and
	4. use the case(s) to perform the task
- In some situations the system must also adapt the case to the target context -- because cases are typically larger scale than rules
- __analogical reasoning__
	- _analogical reasoning_ also operates over specific instances rather than general rules -- however analogies:
		- find mappings between _relational_ structures and use these mappings to draw _relational inferences_
		- whereas case-based uses _attribute-value_ schemes to do _classification_
	- _analogical mapping_ task:
		- Given: a _base_ description of a situation (stated as a set of objects and relations); a _target_ description of a situation
		- _Find_: One or more _mappings_ between the objects and relations in the two descriptions; _extensions_ to the target using elements from its base
	- vs _pattern matching_
		- analogies find mappings between _specific descriptions_ rather than matching variables against constants
		- analogies also allow partial matches -- more costly, especially over large structures
- both analogy and abduction differ from logical reasoning by deduction:
	- both adopt forms of _partial pattern matching_ (rather than all-or-none matching)
	- both use _plausible inference_ (rather than deductive proofs) -- broader coverage
	

#### Domain modelling and planning
- problem solving can be described as _states_, _operators_ (describe search space), and _search control knowledge_ (describe search strategy)
- planning is computationally expensive (even in simplified models) -- caching is usually better
- the 7 _classical assumptions_:
	1. finite proposal domains
	2. omniscience (must be able to determine the truth/falsity of all propositions for a given situation)
	3. actions are always completely deterministic
	4. no exogenous events
	5. all actions take unit time to occur
	6. only qualitative results
	7. all actions occur sequentially
- a problem is described as:
	- a _complete_ description of the initial situation (need to do domain _ontology_ engineering)
	- a description of desired goals
- _state language_
	- using a _closed world assumption_ allows us to use a default (false) value to reduce description
	- predicates whose value can change are __fluents__
	- predicates whose value _can't_ change are __static__ -- can be associated with the problem rather than with each state
	- storing these two separately can save space and time, however we must keep a record of which are static and which are fluent
	- __derived__ predicates values can be derived from the value of other predicates (__primative__ predicates can not) -- allows further space saving by _not_ storing the value of derived predicates
- _goal language_
	- we must explicitly state values we want to be false as `not(foo(X))`
	- things we don't care about are not mentioned in the goal description
- _update language_
	- parameters indicate what objects are relevant to executing the action
	- preconditions describe when the action can be executed
		- expressed in the goal language -- explicitly state what must be true _and_ false
	- the effects describe what happens when the action is executed
	- require a complete description of exactly what changes and does not change -- _frame_ problem
	- can fail if:
		- our preconditions don't capture all the relevant tasks -- _qualification_ problem
		- our effects don't capture all the relevant results -- _ramification_ problem
	- object level predicates are based on state whereas _meta level_ predicates describe domain/state independent functions (e.g. eq, neq, odd)
- the plan is a sequence of steps or states

#### Plan-Space planning
- backward search from the goal
- each node of the search is a _parital plan_
	- a set of partially-instantiated actions
	- a set of constraints
		- _precedence constraint_: _a_ must precede _b_
		- _binding constraint_: equality/inequality
		- _causal link_: use action _a_ to establish precondition _p_ needed by action _b_
- make more and more refinements, until we have a solution
	- resole flaws (_PSP procedure_)
		- _open goal_: an action has an unmet precondition
		- _threat_: an action is capable of deleting a precondition
- -we don't yet know how to generate good heuristsics
- +smaller search space than state-space planner, +when goal node is found solution can be directly extracted


#### Graph planning
- simplify the problem so that search is quicker


#### Machine Learning
- __Machine learning__ is useful for
	- Datamining (e.g. credit worthiness)
	- Poorly understood domains (e.g. face recognition)
	- Programs which must dynamically adapt to changing conditions (e.g. Internet)
- Learning problem needs a __well-specified__ _task_, _performance metric_, and source of training _experience_
- Involves a number of design choices:
	- type of training experience,
	- target function,
	- representation of target function,
	- an algorithm for learning the target function from the training data
- learning involves __searching__ the space of _possible hypotheses_
- different learning methods search different hypothesis spaces (numerical functions, neural networks, decision trees, symbolic rules)
- there are some theoretical results which characterize conditions under which these search methods converge towards an optimal hypothesis


#### Concept learning
- the __inductive hypothesis__ is that any hypothesis found to approximate the target function well over _sufficiently large_ set of training data will also approximate well over _unobserved_ examples
- the __inductive bias__ of an algorithm is a set of assumptions that an algorithm uses to predict outputs for data it has not seen.
- the assumptions that must be added to the observed data to transform the algorithm's outputs into logical deductions.
- concept learning can be seen as search
- General-to-Specific partial ordering of hypotheses can be used to organize search
- Find-S and Candidate-Elimination algorithms
- Inductive learning algorithms are able to classify unseen examples only because of their implicit inductive bias for selecting one consistent hypothesis over another
- an unbiased learner cannot make inductive leaps to classify unseen examples

#### Decision tree learning
- Similar to compression
- use the _information gain_ to select the best attribute at each step
- prefer a tree with less depth && with high information gain attributes at the root
- can use _gain ratio_ to offset effect of bias towards attributes with many values
- __overfitting__ of _h_ is when the hypothesis _h_ has a smaller error than _h'_ over the training data, but a larger error over the entire dataset
	- caused by: noise, small sample size

#### Swarm Intelligence
- __collective behaviors__ that result from the __local interactions__ of individuals with each other and/or their environment
- _many agents_ follow very _simple local rules_
- _no_ centralized control structure
- local interactions lead to the _emergence_ of complex _global behavior_
- the power is in __interactive collaboration__

#### Computational scientific discovery
- a long history of work on this, including methods for constructing:
	- descriptive laws stated as numeric equations
	- explanatory models of structures and processes
- work in this paradigm discovers knowledge stated in formalisms and concepts that are _familiar to scientists_
- the challenge is not with 'big data', but with _complex models_ and _large search spaces_

#### Language + Dialogue
- __language processing__
	- given: a _sentence_, knowledge of _grammar_ and _words_
	- find: a _parse tree_ that breaks the sentence into _constituents_
	- this is only concerned with _grammar_ (not _meaning_)
		- is the sentence valid
- __dialogue processing__
	- given: a _conversation topic_, generic _rules of dialogue_, communicative _actions_ and effects
	- create: _interpretations_ and appropriate _responses_
	- challenges:
		1. parsing utterances (language processing)
		2. integrating dialogue and performance
		3. recognizing or understanding the speakers _intent_
		4. mixed-initiative control of the conversation

#### Cognition, Emotions, and Personality
- _Affect_: the positive or negative aspect of _some experience_
- _Mood_: a global variant of affect for the _entire cognitive system_
- _Emotion_: a mental structure related to goals + beliefs about an event, agent, or object
- _Feeling_: an affective or hormonal response that is associated with an emotion
- we can state conditions for eliciting emotions as abstract rules (e.g. an agent is disappointed if it wanted x, but did not get it)
- _emotional metacognition_ -- emotions play a meta-cognitive role in mental processing (i.e. they inspect basic cognition and alter its course in response)
- _personality metacognition_ -- a stronger effect

