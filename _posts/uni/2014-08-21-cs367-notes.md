---
layout: post
title: CompSci 367 notes
category: uni
excerpt:
---

####Logic
- __Entail__ - _KB |= a_ if and only if _a_ is true in all worlds were KB is true
- __Infer__ - _KB |- i a_ = sentence _a_ can be derived from _KB_ by algorithm _i_
	- _i_ is __sound__ if whenever we infer something from _i_ it is also entailed by the KB
	- _i_ is __complete__ if something is entailed by the KB, then _i_ infers it
- __Conjunctive normal form__ (CNF): conjunction of disjunction of literals e.g. _(A or B) and (B or C)_
- __Negation__ in prolog, when something cannot be proved true it is _false_

####Search
- __Complete__ - always finds a solution if one exists
- __Optimal__ - finds the _best_ solution
- _b_ - branching factor
- _d_ - depth of least cost solution
- _m_ - maximum depth of state space
- _f(n)_ is the _desirability_ of node _n_
- _g(n)_ is the cost from _initialState_ to _n_
- _h(n)_ is the estimate of the distance from _n_ to _goal_
	- __Admissible__ if the estimate is less than the actual cost (i.e. never overestimates)
	- __Consistent__ if obeys the triangle inequality (i.e. _h(n)_ is <= the cost from _n_ to _n'_ + _h(n')_)
	- a heuristic is likely to be better when its _average h-value_ (_r_) is higher
		-  __dominates__ another heuristic when _h1(n) > h2(n)_ for ALL _n_
	- uninformed tree = _b^d_, informed = _b^(d-r)_
	- heuristic can be formed from a __relaxed problem__ (reduce the restrictions)


| | Complete? | Time | Space | Optimal | _f(n)_ | Notes.. |
|:---|:---:|:---:|:---:|:---:|:---:|:---|
| BFS | Y (if _b_ finite) | Exponential | Exponential | Y (if step costs = 1) | | Uses a tonne of space (Graph search) |
| DFS | N (loops/infinite _m_) | Exponential | Linear (only keeps best in mem) | N | | |
| ID DFS | Y | Exponential | Linear (discard after each step) | Y (if step costs = 1) | | DFS + BFS advantages |
| Greedy | N | Exponential | Exponential | N | _h(n)_ | Doesn't care about _g(n)_ |
| A* | Y | Exponential | Exponential | Y (if _h_ is admissible + consistent) | _g(n) + h(n)_ | |
| IDA* | Y | Exponential | Linear | Y | _g(n) + h(n)_ | Iterates on the _f-limit_ - start with _h(init)_ |
| Weighted A* | Y | Exponential | Exponential | Y | _g(n) + h(n) * w_ | will be no worse than _w_ times as costly as optimal |
| Bidirectional A* Front-to-Back | Y | Exponential | Exponentially smaller (_b^(d/2)_) | Y | _g(n) + h(n)_ | _h(n)_ estimates diastase to the opposite terminal (init or goal), keeps searching for optimal |
| Bidirectional A* Front-to-Front | Y | Exponential | Exponentially smaller (_b^(d/2)_) | Y | _g(n) + h(n)_ | _h(n)_ estimates diastase to the opposite frontier, optimal on first collision!, cost of computing _h_ grow exponentially |
| Min-Max | Y | Exponential | Linear | Y (against optimal opponent) | _minmax value_ | |
| Min-Max _a-b_ pruning | Y | Exponentially smaller (_b^(m/2)_) | Linear | .. | _minmax value_ | _doubles_ depth which can be done in the same time |

- __Monte Carlo Tree Search__ plays out the rest of a game randomly, thousands of times, picks the one with the highest win rate. (explores the whole problem space)

####Local Search
- __Hill climbing__ algorithm
	- always moves toward a maxima - can get stuck on a local maxima, missing the global maximum
	- add _random-restarts_ when you get stuck - trivially complete (depends on the shape of the state-space landscape)
- __Simulated annealing__ search - allows some 'bad' moves to escape local maxima, but _gradually decreases_ their size and frequency
- __Local beam__ search
	- start with _k_ randomly generated states
	- better than random restarts as information is shared -- but can get concentrated in a small region
- __Stochastic beam__ search - choose _k_ successors randomly, biased towards good ones (natural selection)

####Genetic algorithms
- requires: reproduction, population, variety, difference in ability to survive
- reproduce with a _probability proportional to their fitness_
- __overcrowding__ can happen if one individual is too dominant


####Constraint satisfaction problems (CSP)
- _state_ is defined by __variables__ _Xi_ with _values_ from __domain__ _Di_
- _goal test_ is a set of __constraints__ specifying allowable combinations of values for subsets of variables
	- __Unary__ constraints involve a single variable (_X != 5_)
	- __Binary__ constraints involve variable pairs (_X != Y_)
	- __Higher-order__ 3 or more variables
- __Incremental search__ - assign values to variables that do not conflict with current assignment
- __Backtracking__ search (DFS)
	- choose the most constrained variable i.e. with the fewest legal values (_minimum remaining values (MRV)_ heuristic)
	- __Forward checking__ - keep track of legal values for all variables, abort when a variable has none remaining
	- __Arc consistency__ - also keeps track of the affect that forward checking has on neighbours (detects failure earlier)	



----
----
##Week 6 - 12
####Decision making & choice
- The __choice task__:
	- Given: some _goals/objectives_; a set of _candidates relevant to these aims_; _descriptions_ for each
	- Find: one or more candidates to _select/carry out_
- the ability to select from alternatives forms the _basis of more complex intelligence_ and leads naturally to the idea of _agency_
- _routine choices_ (i.e. which clothes to wear, what to eat) vs _complex decisions_ (i.e. which house to buy)
- decision making paradigms:
	- Logical reasoning (uncommon)
	- __Decision theory__ (_prescriptive_)
		- Given:
			- a set of _K_ alternatives (_A1, ..., AK_) from which to choose
			- a set of _N_ attribute values (_VJ1, ..., VJN_) associated with each alternative (_AJ_)
			- a set of _N_ weights (_W1, ..., WN_) that specify the _importance_ of each attribute
		- we should calculate the _utility value_ of each alternative
			- _UJ_ = sum of each _W * VJ_ (weight x value)
		- if the value of an attribute is unknown use a strategy that is: optimistic (always best result), pessimistic (always worst), regret-based (find difference in results), or expected-value (weighted average -- most widely used e.g., 30% chance of x + 10% chance of y = _0.3x + 0.1y = ex_)
	- __Heuristic choice__ (_descriptive_)
		- based on the idea that humans do _not make optimal choices_ but instead __satisfice__ (i.e., select an _acceptable_ alternative based on an _aspiration level_)
		- we draw on _heuristics_ (or 'rules of thumb') that produce __acceptable results__ with __limited effort__
		- humans retrieve _chunks_ of relevant memory (from pattern matching) to produce associated responses very rapidly
		- AI defines two forms of heuristics:
			- __Symbolic heuristics__ -- rules or relational patterns (as in human cognition, _chunks_ -- used in heuristic choice theory)
			- __Numeric heuristics__ -- arithmetic combinations of attributes (similar to utility functions -- used to find optimal choices and in search)
		- simple heuristics (independent of the domain): _recognition_ (recognized alternatives are better), _fluency_ (speed of recognition), _dominance_ (on the most important attribute), _tallying_ (most positive cues), _hedging_ (allocate equally to each alternative), _imitate the majority_ (follow others in group)
		- we use heuristics because the are _efficient_ and _effective_
- in reality, we must also: _find a problem_ to address (posed by others or generated from knowledge), _generate candidates_ (either from environment or memory), _produce a description_ of each candidate (often _inferred_ from reasoning methods)

####Reactive control for routine behaviour
- one obvious way to support _sequential decision making_ is to invoke the basic process repeatedly
- this leads to the __reactive control__ task (which we apply iteratively to produce a sequence)
	- Given: a description of the _environment_; related _goals_ [+ _beliefs_, or _mental states_]
	- _Select_: an appropriate _action_ to execute in the environment
- routine control is _conditional_, which gives it great flexibility. this can be done by direct mappings from perception to action -- known as __stimulus-response__ (does not take advantage of mental states)
	- this can be quite effective for well-defined tasks (i.e. landing a plane, driving a car) where there is _clear mappings_ between classes of situation and appropriate responses
	- used in:
		- _Control theory_ -- mathematical; measures attributes and controls variables based on calculations (e.g. balancing a pole)
		- _Behaviourist psychology_ -- behaviourist paradigm; stimulus-response pairs directly link to actions; process by: retrieving stimulus-response pair to match situation, carry out the response, alter strength based on reward; rejects the idea of mental structures
		- _Reactive control in AI_ -- encode knowledge as a set of _situation-action_ rules; retrieve a pattern that matches the current situation, execute the action
			- like behavioural these systems have no explicit short-term _beliefs or goals_
	- in reality, humans draw _inferences_ about current situation, have _memories_ of past decisions, knowledge of _order_ of activities, breakdown activities to _subactivities_, take _goals_ into account
	- extensions can attempt to address these issues, but the stimulus-response paradigm has inherent limitations
- organising extended activities into __hierarchical structures__: +each component is _simple_, +_modular_ +_reusable_ components, +_composable_ dynamically
- __Hierarchical Task Networks__ (HTNs)
	- comprise of a set of _methods_ with:
		- a _task predicate_ (and args); _conditions_ under which the method applies; _subtasks_ that allow you to implement the method; [_effects_ the method produces]
	- imposes a _hierarchical_, _sequential_, _conditional_ structure on activities
	- this produces an _AND/OR tree_, as in prolog, but over activities
	- __executing HTNs__ 
		- given some task _T_, on each cycle:
			- infer a set of beliefs from stimuli (using conceptual rules)
			- find (through the hierarchy) a _path_ of applicable methods
			- execute
		- traverses the AND/OR tree over time -- this _reactive_, but continues along the current path when possible
	- -complex syntax (hard to build and maintain) -require a domain expert to manually enter the knowledge, -learning HTNs slower than learning classification

####Production systems
- the _production system_ paradigm incorporates _internal_ perceptions and actions -- cognition as _conditional mental action_
- often used to model high-level cognition in people
	- support mental activities that make humans unique
	- combine _parallel retrieval_ with _sequential decisions_
	- balance _stimulus-driven_ and _goal-driven_ behaviour
	- analysis for symbolic tasks
	- _modular representation_ supports structural learning
- made up of 2 main components
	- _Production memory_ containing generalized _rules_ that specify domain knowledge as conditional responses
		- similar to stimulus-response pairs
		- _condition_ side (with conditions that must match working memory)
		- _action_ sides (one or more actions that alter memory or the world)
	- _Working memory_ that contains specific _elements_
		- internal stimuli -- encoding the systems beliefs and goals
		- changes as the program runs
- can achieve the same effects as HTNs by adding 'tasks' to working memory that lead to other rule match on later cycles
- executes with successive _recognize-act cycles_
	- match each rules conditions with working memory
	- select one (or more) of the matched rules to execute
		- _conflict resolution_ can be: match more recent elements, match more specific sets, more conditions, rules added earlier. this can lead to differing behaviour in the same situation
	- execute the actions
- _forward chaining_ of rules can produce results that they could not in isolation

####Causal models + Qualitative reasoning
- _Causal prediction/simulation_ task:
	- Given: a set of _entities_ and associated _attributes_, a set of _relations/rules_ that relate them, a set of _external influences_
	- _Find_: the _resulting effects_ on attributes of interest
- this makes a _mental model_ -- analogous to a physical model, but are _internal_ structures
- definition: _X_ __causally influences__ _Y_ if a change in _X_'s value results in a change in _Y_'s value (provided that other variables are held constant)
- n.b. this does not mean that _X_ is the only causal influence on _Y_
- e.g.

```
gas_tax         +gas_price
oil_production  -gas_price

gas_price  -traffic
tolls      -traffic

traffic  +pollution  +lung_disease
```

- definition: _X_ causally influences _Y_ in a __dynamic manner__ if a change in _X_ results in a change in _Y_'s _derivative wrt time_
- qualitative but dynamic causal model to generate __Qualitative Envisionments__
	- include: initial qualitative state, set of possible qualitative _successor states_, set of _transitions_
	- envisionment encodes the set of _possible_ trajectories
	- _nondeterministic_ because they abstract details
	- -multiple influences can cause weak predictions, -difficult to visualize and interpret


####Explanations
- __explanation generation__ task:
	- Given: set of general _knowledge elements_; set of _observed facts_
	- _Find_: one (or more) _explanation_ that relate the observations (_connected_ to others through general _knowledge_)
- _understand_ often means explained
- we can use causal relations to create a _deductive causal explanation_ (e.g. oil production leads to +lung disease)

####Abductive reasoning
- __abductive inference__ task:
	- Given: set of general rules or other knowledge elements, set of specific _observed facts_
	- _Find_: one (or more) explanation that relate observations and _plausible assumptions_
		- observed facts + specific default assumptions + _rule instances_ that link facts and assumptions
- key difference: the creation of _default assumptions_ that complete the account
- take the form of _proof trees_, but the assumptions are _not_ deductively valid
- inference to the best explanation? too concerned with optimality -- humans often arrive at incomplete/incorrect explanations through abduction
- e.g. __abductive explanation__

```prolog
%% background knowledge
good_mood(X) :- did_well_on(X,Y).
did_well_on(X,Y) :- exam(Y), study(X,Y), take(X,Y).

%% suppose we observe
good_mood(john).	exam(e).	take(john,e).

%% suppose we want to explain why john is in a good mood
%% if we make one assumption:
study(john,e).

%% we could derive good_mood(john) from this assumption and the observations
good_mood(john) :- /** observation to explain **/ 
	did_well_on(john,e) :- 
		exam(e),
		study(john,e), /** assumption **/
		take(john,e).
```

- query-driven, _backward-chaining_ deduction: start with fact _F_ (to explain) and chain through rules that unify with _F_ -- first using facts when possible then make default assumptions
- _prefer_: +simpler explanations; +more probable accounts; +minimum weight assumptions; +_coherent_ explanations (those which _relate more observations_)
- data-driven, _forward-chaining_ (less common): start with facts (to relate) -- does not require a top-level fact (to explain)
- an adbuctive system should be able to retract assumptions (when new information is introduced) through a process of _belief revision_
- abductive inference is central to _plan understanding_, story understanding, moral judgement, and science

####Case-based and Analogical reasoning
- humans are able to take advantage of background knowledge from specific experiences stored in memory (when general rules are unknown/unavailable)
- operates using 4 main stages:
	1. input some query or problem;
	2. retrieve relevant cases from memory;
		- typically based on _similarity_ between the case and query/problem
	3. select which case(s) to utilize; and
	4. use the case(s) to perform the task
- In some situations the system must also adapt the case to the target context -- because cases are typically larger scale than rules
- __analogical reasoning__
	- _analogical reasoning_ also operates over specific instances rather than general rules -- however analogies:
		- find mappings between _relational_ structures and use these mappings to draw _relational inferences_
		- whereas case-based uses _attribute-value_ schemes to do _classification_
	- _analogical mapping_ task:
		- Given: a _base_ description of a situation (stated as a set of objects and relations); a _target_ description of a situation
		- _Find_: One or more _mappings_ between the objects and relations in the two descriptions; _extensions_ to the target using elements from its base
	- vs _pattern matching_
		- analogies find mappings between _specific descriptions_ rather than matching variables against constants
		- analogies also allow partial matches -- more costly, especially over large structures
- both analogy and abduction differ from logical reasoning by deduction:
	- both adopt forms of _partial pattern matching_ (rather than all-or-none matching)
	- both use _plausible inference_ (rather than deductive proofs) -- broader coverage
	
