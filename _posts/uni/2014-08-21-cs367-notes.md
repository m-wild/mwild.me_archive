---
layout: post
title: CompSci 367 notes
category: uni
excerpt:
---

####Logic
- __Entail__ - _KB |= a_ if and only if _a_ is true in all worlds were KB is true
- __Infer__ - _KB |- i a_ = sentence _a_ can be derived from _KB_ by algorithm _i_
	- _i_ is __sound__ if whenever we infer something from _i_ it is also entailed by the KB
	- _i_ is __complete__ if something is entailed by the KB, then _i_ infers it
- __Conjunctive normal form__ (CNF): conjunction of disjunction of literals e.g. _(A or B) and (B or C)_
- __Negation__ in prolog, when something cannot be proved true it is _false_

####Search
- __Complete__ - always finds a solution if one exists
- __Optimal__ - finds the _best_ solution
- _b_ - branching factor
- _d_ - depth of least cost solution
- _m_ - maximum depth of state space
- _f(n)_ is the _desirability_ of node _n_
- _g(n)_ is the cost from _initialState_ to _n_
- _h(n)_ is the estimate of the distance from _n_ to _goal_
	- __Admissible__ if the estimate is less than the actual cost (i.e. never overestimates)
	- __Consistent__ if obeys the triangle inequality (i.e. _h(n)_ is <= the cost from _n_ to _n'_ + _h(n')_)
	- a heuristic is likely to be better when its _average h-value_ (_r_) is higher
		-  __dominates__ another heuristic when _h1(n) > h2(n)_ for ALL _n_
	- uninformed tree = _b^d_, informed = _b^(d-r)_
	- heuristic can be formed from a __relaxed problem__ (reduce the restrictions)


| | Complete? | Time | Space | Optimal | _f(n)_ | Notes.. |
|:---|:---:|:---:|:---:|:---:|:---:|:---|
| BFS | Y (if _b_ finite) | Exponential | Exponential | Y (if step costs = 1) | | Uses a tonne of space (Graph search) |
| DFS | N (loops/infinite _m_) | Exponential | Linear (only keeps best in mem) | N | | |
| ID DFS | Y | Exponential | Linear (discard after each step) | Y (if step costs = 1) | | DFS + BFS advantages |
| Greedy | N | Exponential | Exponential | N | _h(n)_ | Doesn't care about _g(n)_ |
| A* | Y | Exponential | Exponential | Y (if _h_ is admissible + consistent) | _g(n) + h(n)_ | |
| IDA* | Y | Exponential | Linear | Y | _g(n) + h(n)_ | Iterates on the _f-limit_ - start with _h(init)_ |
| Weighted A* | Y | Exponential | Exponential | Y | _g(n) + h(n) * w_ | will be no worse than _w_ times as costly as optimal |
| Bidirectional A* Front-to-Back | Y | Exponential | Exponentially smaller (_b^(d/2)_) | Y | _g(n) + h(n)_ | _h(n)_ estimates diastase to the opposite terminal (init or goal), keeps searching for optimal |
| Bidirectional A* Front-to-Front | Y | Exponential | Exponentially smaller (_b^(d/2)_) | Y | _g(n) + h(n)_ | _h(n)_ estimates diastase to the opposite frontier, optimal on first collision!, cost of computing _h_ grow exponentially |
| Min-Max | Y | Exponential | Linear | Y (against optimal opponent) | _minmax value_ | |
| Min-Max _a-b_ pruning | Y | Exponentially smaller (_b^(m/2)_) | Linear | .. | _minmax value_ | _doubles_ depth which can be done in the same time |

- __Monte Carlo Tree Search__ plays out the rest of a game randomly, thousands of times, picks the one with the highest win rate. (explores the whole problem space)

####Local Search
- __Hill climbing__ algorithm
	- always moves toward a maxima - can get stuck on a local maxima, missing the global maximum
	- add _random-restarts_ when you get stuck - trivially complete (depends on the shape of the state-space landscape)
- __Simulated annealing__ search - allows some 'bad' moves to escape local maxima, but _gradually decreases_ their size and frequency
- __Local beam__ search
	- start with _k_ randomly generated states
	- better than random restarts as information is shared -- but can get concentrated in a small region
- __Stochastic beam__ search - choose _k_ successors randomly, biased towards good ones (natural selection)

####Genetic algorithms
- requires: reproduction, population, variety, difference in ability to survive
- reproduce with a _probability proportional to their fitness_
- __overcrowding__ can happen if one individual is too dominant


####Constraint satisfaction problems (CSP)
- _state_ is defined by __variables__ _Xi_ with _values_ from __domain__ _Di_
- _goal test_ is a set of __constraints__ specifying allowable combinations of values for subsets of variables
	- __Unary__ constraints involve a single variable (_X != 5_)
	- __Binary__ constraints involve variable pairs (_X != Y_)
	- __Higher-order__ 3 or more variables
- __Incremental search__ - assign values to variables that do not conflict with current assignment
- __Backtracking__ search (DFS)
	- choose the most constrained variable i.e. with the fewest legal values (_minimum remaining values (MRV)_ heuristic)
	- __Forward checking__ - keep track of legal values for all variables, abort when a variable has none remaining
	- __Arc consistency__ - also keeps track of the affect that forward checking has on neighbours (detects failure earlier)	



----
----
##Week 6 - 12
####Decision making & choice
- The __choice task__:
	- Given: some _goals/objectives_; a set of _candidates relevant to these aims_; _descriptions_ for each
	- Find: one or more candidates to _select/carry out_
- the ability to select from alternatives forms the _basis of more complex intelligence_ and leads naturally to the idea of _agency_
- _routine choices_ (i.e. which clothes to wear, what to eat) vs _complex decisions_ (i.e. which house to buy)
- decision making paradigms:
	- Logical reasoning (uncommon)
	- __Decision theory__ (_prescriptive_)
		- Given:
			- a set of _K_ alternatives (_A1, ..., AK_) from which to choose
			- a set of _N_ attribute values (_VJ1, ..., VJN_) associated with each alternative (_AJ_)
			- a set of _N_ weights (_W1, ..., WN_) that specify the _importance_ of each attribute
		- we should calculate the _utility value_ of each alternative
			- _UJ_ = sum of each _W * VJ_ (weight x value)
		- if the value of an attribute is unknown use a strategy that is: optimistic (always best result), pessimistic (always worst), regret-based (find difference in results), or expected-value (weighted average -- most widely used e.g., 30% chance of x + 10% chance of y = _0.3x + 0.1y = ex_)
	- __Heuristic choice__ (_descriptive_)
		- based on the idea that humans do _not make optimal choices_ but instead __satisfice__ (i.e., select an _acceptable_ alternative based on an _aspiration level_)
		- we draw on _heuristics_ (or 'rules of thumb') that produce __acceptable results__ with __limited effort__
		- humans retrieve _chunks_ of relevant memory (from pattern matching) to produce associated responses very rapidly
		- AI defines two forms of heuristics:
			- __Symbolic heuristics__ -- rules or relational patterns (as in human cognition, _chunks_ -- used in heuristic choice theory)
			- __Numeric heuristics__ -- arithmetic combinations of attributes (similar to utility functions -- used to find optimal choices and in search)
		- simple heuristics (independent of the domain): _recognition_ (recognized alternatives are better), _fluency_ (speed of recognition), _dominance_ (on the most important attribute), _tallying_ (most positive cues), _hedging_ (allocate equally to each alternative), _imitate the majority_ (follow others in group)
		- we use heuristics because the are _efficient_ and _effective_
- in reality, we must also: _find a problem_ to address (posed by others or generated from knowledge), _generate candidates_ (either from environment or memory), _produce a description_ of each candidate (often _inferred_ from reasoning methods)

####Reactive control for routine behaviour
- one obvious way to support _sequential decision making_ is to invoke the basic process repeatedly
- this leads to the __reactive control__ task (which we apply iteratively to produce a sequence)
	- Given: a description of the _environment_; related _goals_ [+ _beliefs_, or _mental states_]
	- _Select_: an appropriate _action_ to execute in the environment
- routine control is _conditional_, which gives it great flexibility. this can be done by direct mappings from perception to action -- known as __stimulus-response__ (does not take advantage of mental states)
	- this can be quite effective for well-defined tasks (i.e. landing a plane, driving a car) where there is _clear mappings_ between classes of situation and appropriate responses
	- used in:
		- _Control theory_ -- mathematical; measures attributes and controls variables based on calculations (e.g. balancing a pole)
		- _Behaviourist psychology_ -- behaviourist paradigm; stimulus-response pairs directly link to actions; process by: retrieving stimulus-response pair to match situation, carry out the response, alter strength based on reward; rejects the idea of mental structures
		- _Reactive control in AI_ -- encode knowledge as a set of _situation-action_ rules; retrieve a pattern that matches the current situation, execute the action
			- like behavioural these systems have no explicit short-term _beliefs or goals_
	- in reality, humans draw _inferences_ about current situation, have _memories_ of past decisions, knowledge of _order_ of activities, breakdown activities to _subactivities_, take _goals_ into account
	- extensions can attempt to address these issues, but the stimulus-response paradigm has inherent limitations
- organising extended activities into __hierarchical structures__: +each component is _simple_, +_modular_ +_reusable_ components, +_composable_ dynamically
- __Hierarchical Task Networks__ (HTNs)
	- comprise of a set of _methods_ with:
		- a _task predicate_ (and args); _conditions_ under which the method applies; _subtasks_ that allow you to implement the method; [_effects_ the method produces]
	- imposes a _hierarchical_, _sequential_, _conditional_ structure on activities
	- this produces an _AND/OR tree_, as in prolog, but over activities
	- __executing HTNs__ 
		- given some task _T_, on each cycle:
			- infer a set of beliefs from stimuli (using conceptual rules)
			- find (through the hierarchy) a _path_ of applicable methods
			- execute
		- traverses the AND/OR tree over time -- this _reactive_, but continues along the current path when possible
	- -complex syntax (hard to build and maintain) -require a domain expert to manually enter the knowledge, -learning HTNs slower than learning classification

####Production systems
- the _production system_ paradigm incorporates _internal_ perceptions and actions -- cognition as _conditional mental action_
- often used to model high-level cognition in people because they support:
	