---
layout: post
title: CompSci 367 notes
excerpt:
---
{% include mathjax.html %}

##Pat Riddle
Lectures 01 through 08

- Acting rationally
	- Rational behaviour: doing the right thing (expected to maximize the goal)
	- Doesn't necessarily entail 'thinking'
- Rational agent
	- agent is an entity that _perceives_ and _acts_
	- abstractly: a function from percept sequence to actions
	- computational limitations make perfect rationality unachievable

####Problems
- _Single-state_ problem
	- deterministic, fully-observable
	- agent knows exactly which state it will be in
	- solution is a sequence
- _Sensorless_ problem (Conformant problem)
	- non-observable
	- agent may have no idea where it is
	- solution (if any) is a sequence
- _Contingency_ problem
	- non-deterministic and/or partially observable
	- percepts provide new information about current state
	- solution is a contingency plan or policy
	- often interleave search and execution
- _Exploration_ problem ('online')
	- unknown state space
	- solution depends on type of problem, same puzzle could have multiple solutions if we do or do not know where we are (single-state vs. sensorless)


- _Problem formulation_ defined by:
	- Initial state
	- Actions of successor function
	- Goal test
	- Path cost (additive)
	- Solution is a sequence of actions (form init to goal)
	- _must_ abstract state space (real world is far too complex)

- Implementation: states vs nodes
	- __state__ is representation of a physical configuration
	- __node__ is a data structure constituting part of a search tree, including _state_, pointer to parent node, _action_, path code _g(x)_, depth


- Search strategies
	- defined by order of node expansion
	- evaluated by criteria:
		- _Completeness_ -- does it always find a solution if one exists
		- _Time complexity_ -- number of nodes generated/expanded
		- _Space complexity_ -- maximum number of nodes in memory
			- $b$ -- maximum branching factor
			- $d$ -- depth of the least cost solution
			- $m$ -- maximum depth of the state space (may be infinite)
		- _Optimality_ -- does it always find the best solution

####Uninformed search
- use only the information available in the _problem definition_
- __Breadth-first search__ (BFS)
	- expand the _shallowest_ unexpanded node
	- implementation: fringe is a FIFO queue, new successors go at the end
	- Complete (if branching factor is finite)
	- Time: $O(b^d)$
	- Space: $O(b^d)$ -- a big problem
	- Optimal (if all step costs are the same and non-negative), not optimal in general
- __Depth-first search__ (DFS)
	- Expand the _deepest_ unexpanded node
	- implementation: fringe is a LIFO queue, successors at the front
	- NOT complete (fails with loops or infinite depth)
	- Time: $O(b^m)$ -- terrible if _m >> d_
	- Space: $O(bm)$ -- linear space (only keep the best solution in memory)
	- NOT optimal
- __Iterative Deepening DFS__
	- Complete (like BSF)
	- Time: $O(b^d)$
	- Space: $O(bd)$ -- discard memory after each step
	- Optimal (if all step costs are the same and non-negative)
- __Graph search__
	- like tree search by you keep a list of all the states you've visited so you don't revisit states

####Logical agents
- can be viewed at the _knowledge_ level (what they know) or the _implementation_ level (data structures in KB and algorithms to manipulate them)
- agent must be able to represent states, actions, incorporate new percepts, update internal representations of the world, deduce hidden properties of the world, deduce appropriate actions
- __World characterization__
	- Observable -- know where you are
	- Deterministic -- outcomes exactly specified; no random errors
	- Episodic -- does the history matter?
	- Static -- world doesn't change
	- Discrete
	- Single agent
- logic in general
	- _syntax_ defines the sentences in the language
	- _semantics_ define the 'meaning' of the sentences
- __Entailment__
	- one thing follows from another
	- a KB entails a sentence if and only if that sentence is true in all worlds where the KB is true
	- entailment is a relationship between sentences (ie. syntax) this is based on semantics
- __Models__
	- _formally structured worlds_ with respect to which truth can be evaluated
	- _m_ is a model of sentence _a_ if _a_ is true in _m_
- __Inference__
	- _KB |- i a_ = sentence _a_ can be derived from _KB_ by procedure _i_
	- consequences of _KB_ are a haystack, _a_ is a needle
	- _entailment_ = needle in a haystack -- _inference_ = finding it
	- __soundness__ _a_ is sound if whenever _KB_ infers _a_, _KB_ also entails _a_
	- __completeness__ _a_ is complete if whenever _KB_ entails _a_, _KB_ also infers _a_
	- inference by enumeration
		- depth-first enumeration of all modes is sound and complete
		- for _n_ symbols
			- time complexity is $O(2^n)$ (boolean assignment)
			- space complexity is $O(n)$ (depth-first)
	- legitimate (sound) generation of new sentences from old
	- proof -- a sequence of inference rule applications
- Logic
	- a sentence is __valid__ if it is true in ALL models
	- a sentence is __satisfiable__ if it is true in some model
	- a sentence is __unsatisfiable__ if it is true in NO model
- __Forward chaining__
	- _Horn form_ -- _KB_ is conjunction of Horn Clauses (proposition symbol of conjunction of symbols) 
	- Fire and rule whose premises are satisfied in the KB, add it's conclusion to the KB until goal query is found
	- _data-driven_, automatic, unconscious processing
	- may do lots of work that is irrelevant to the goal
- __Backward chaining__
	- Work backwards from the query _q_
	- avoids loops -- check if new subgoal is already on the goal stack
	- avoid repeated work -- check if new subgoal has already failed or been proved true
	- also avoids irrelevant work
	- _goal-driven_ and appropriate for problem solving
- __Conjunctive Normal Form__ (CNF): conjunction of disjunction of literals eg. _(A or B) and (B or C)_
- __complementary literals__ -- pairs of literals that contradict eg. _A and not(A)_

####First Order logic
- _propositional logic_ is declarative, allows disjunction and negations, is compositional, context-independent, and has very limited expressive power
- _first order logic_ contains facts, objects, relations; atomic sentences; complex sentences (made from atomic sentences using connectives)
- truth in FOL
	- sentences are true with respect to a model and an interpretation -- model contains objects (domain elements)
	- computing entailment by enumerating FOL models isn't easy (eg. how do you validate ALL X, ALL Y ... enumerate through everything!)
	- Quantifiers can be commutative if they are the same
	- Quantifier duality -- things you can say with one, you can say with the other
- __diagnostic rule__ -- infer cause from effect
- __causal rule__ -- infer effect from cause
- situation calculus is used to represent change in FOL (can add a NOW predicate to denote a situation)
- describing actions
	- __Effect axiom__ -- describe changes due to action
	- __Frame axiom__ -- describe non-changes due to action
- problems with actions
	- _Frame problem_ -- find an elegant way to handle non-change
		- representation -- avoid frame axioms
		- inference -- avoid repeated 'copy overs' to keep track of state
	- _Qualification problem_ -- true descriptions of real actions require endless caveats
	- _Ramification problem_ -- real actions have many secondary actions
	- _Successor-state axioms_ solve that representational frame problem

- Entailment in FOL is __semidecidable__ - algorithms exist to say yes to every entailed sentence, but no algorithm exists to say no to every _nonentailed_ sentence
- __Database indexing__ allows $O(1)$ retrieval of known facts -- forward chaing is widely used in deductive databases


------

##Mike Barley
Lectures 07 through 12

####Heuristic Search I
- The core idea is that it guides the problem solver towards the solution
- Like saying "hot" or "cold"
- We begin with an uninformed problem solver
- Formal definition of what it means for a sequence of states to be a solution to a problem

```
solution(+problem(InitState, GoalTest), ?Solution)

Solution 	is a solution to the problem if and only if
			Solution is a non-empty sequence of states
			such that the Solution's first state is InitState of the problem,
				the last state in Solution satisfies the GoalTest,
				and each state in Solution is a successor to its preceding state
```

- Translation in prolog: (see L08-DFS.pl)

```prolog
solution(problem(InitState, GoalTest), [InitState]) :- 
	Goal = [GoalTest, InitState], call(Goal).

solution(problem(InitState, GoalTest), [InitState, NextState | RestOfSolution]) :-
	successor(InitState, NextState),
	solution(problem(NextState, GoalTest), [NextState | RestOfSolution]).
```

- Example:

```prolog
% Domain definition:
successor(northland, auckand).
successor(auckland,hamilton).
successor(hamilton, rotorua).
successor(hamilton, wellington).
successor(wellington, chch).

% Goal Definition:
reachedHome(northland).
```

####Tree Search
- Keeps a record of current path and choice points along the path (to visit if current path abandoned)
	- When goal state is found, solution is simply the current path
- __Naive__ Tree search
	+ only needs to store current path
	+ simple logic
	- non-optimal solution
	- repeats seach for duplicate states
	- incomplete (for infinite graphs)

####Graph search
- breadth-first search
	+ does glabal check for duplicates
	+ complete
	- keeps whole graph in memory, solution must be extracted when found
	- more complex logic

```prolog
/* solution(+Problem, -Solution) */ 
solution(problem(InitialState, Goal), Solution) :-
	solution(Goal, [node(InitialState, nil)], [ ], Solution).

/* solution(+Goal, +Fringe, +Closed, -Solution) */
solution(Goal, [node(State, ParentState) | _], Closed, Solution) :-
	call(Goal, State),
	extractSolution(ParentState, Closed, [State], Solution).

solution(Goal, [node(State, Parent) | RestNodes], Closed, Solution) :- 
	findall(NeighborNode,
				newNeighborNode(State, Closed, NeighborNode),
				NeighboringNodes),
	updateClosed(State, Closed, NewClosed),
	orderFringe(RestNodes, NeighboringNodes, NewFringe),
	solution(Goal, NewFringe, [node(State, Parent) | NewClosed], Solution).
```

####Search strategies
- defined by the _order of node expansion_
- let $g(n)$ be the cost of _n_'s path from the initial state
- assume all edges cost 1 then:
	- DFS picks node with _highest g-value_
	- BFS picks node with _lowest g-value_
- __Best-first search__ strategy
	- picks the _best_ node to expand next
	- different criteria
		- Time to find solution
		- Quality of solution
		- Combination of both
	- for this we need additional information
	- use function $f(n)$ is an estimate of the _desirability_ of a node
		- Uninformed search: __?? might be backwards ??__
			- DFS: $f(n) = -g(n)$
			- BFS: $f(n) = g(n)$
- __Informed search__ strategies use info beyond just the problem description
	- Let $h(n)$ be a "function" that guesses how fan _n_ is from its nearest goal state
- __Best-first informed search__ strategies
	- Greedy Search
	- A*
	- Iterative Deepening A* (IDA*)
	- Weighted A*

- $f(n)$ is the _desirability_ of node _n_
- $g(n)$ is the cost of _n_'s path from the _initial state_
- $h(n)$ is the estimate of the distance from _n_ to the _goal state_

####Greedy Search
- Evaluation function: $f(n) = h(n)$
- Greedy search expands the node that _appears_ to be closest to the goal
+ With a decent enough heuristic, goes straight to the goal
+ Best case: linear time and space
- NOT complete (same problem as DFS with infinite graphs)
- $O(b^m)$ time (but improved by heuristic)
- $O(b^m)$ space
- NOT optimal

```prolog
/* solution(+Heuristic, +Goal, +Fringe, +Closed, -Solution) */

solution(_Heuristic, Goal, [Node | _], Closed, Solution) :-
	node(Node, State, ParentState, _FValue),
	test(Goal, State),
	extractSolution(ParentState, Closed, [State], Solution).

solution(Heuristic, Goal, [Node | RestNodes], Closed, Solution) :-
	nodeState(Node, State),
	findall(NeighborNode,
			newNeighborNode(State, Heuristic,
							[Node | Closed], NeighborNode),
			NeighboringNodes),
	orderFringe(RestNodes, NeighboringNodes, NewFringe),
	solution(Heuristic, Goal, NewFringe, [Node | Closed], Solution).

```

- Greedy's problem is it doesn't care how expensive the current path already is, $g(n)$
- So we can use $f(n) = g(n) + h(n)$

####A* algorithm
- Components:
	- __solution(+Heuristic, +GoalTest, +Fringe, +Closed, -Solution)__
	- Fringe is the list of nodes still to be expanded, ordered by $f(n)$
	- Closed is the list of expanded states, contains $h(n)$ and $g(n)$ per state
	- Solution is a list of states that solved the problem
- General algorithm:

```
solution(HFun, Goal, [Node|RestFringe], Closed, Solution)
	if (Node satisfies Goal)
		then extract Solution from Closed
	else if (Node already expanded, ie. in Closed)
		then solution(Hfun, Goal, RestFringe, Closed, Solution)
	else
		let Nodes be all the 'new' neighbours of Node (with f-values, parents, etc.)
		sort(Nodes + RestFringe) by f-value into NewFringe
		solution(Hfun, Goal, NewFringe, [Node|Closed], Solution).
```

- Optimal if: a node's _f-value_ is the lower bound of all solutions reachable from that node
- A heuristic is __admissible__ if for every node _n_, $h(n) <=$ the optimal cost to reach goal state from _n_
	- e.g. the straight line distance never overestimates the distance by road
- What happens if a long path to a state persistently predicts that it is close to a goal, while a shorter path has a much more accurate estimate?
	- we can end up at the same node by taking the longer path first!
- A heuristic is __consistent__ if for every node _n_, every successor _n'_ of _n_ is generated by action _a_
	- $h(n) <= c(n, a, n') + h(n')$
	- where $c(n, a, n')$ is the cost of executing action _a_ in state _n_ obtaining state _n'_
	- Triangle inequality, the straight-line distance from _n_ to _n'_ is less than or equal to the distance to a third point _m_ then to _n'_
	- if _h_ is consistent, the _f(n)_ is non-decreasing (i.e., _monotone_) along all paths
- If _h_ is _admissible_ and _consistent_ then A* is guaranteed to be optimal
- We need the Closed list to: extract the solution, and avoid searching the same space twice
	- If _h_ is consistent then the first time we pick a state to be expanded, we are guaranteed that we have found the lowest cost path to that state
- A* in prolog:

```prolog
/* solution(+Heuristic, +Goal, +Fringe, +Closed, ?Solution) */ 
solution(_Heuristic, Goal, [Node | _], Closed, Solution) :-
	nodeState(Node, State),
	call(Goal, State),
	extractSolution(ParentState, Closed, [State], Solution).

solution(Heuristic, Goal, [Node | RestNodes], Closed, Solution) :-
	nodeState(Node, State),
	(findNodeWithState(State, Closed, _) ->
		solution(Heuristic, Goal, RestNodes, Closed, Solution)
	;
		nodeGValue(Node, GValue),
		findall(NeighborNode,
				newNeighborNode(State, GValue, Heuristic,
								[Node | Closed], NeighborNode),
				NeighboringNodes),
		append(RestNodes, NeighboringNodes, UnsortedNewFringe),
		samkeysort(UnsortedNewFringe, NewFringe),
		solution(Heuristic, Goal, NewFringe, [Node | Closed], Solution)).
```

- Properties of A*
	- Complete (unless there are infinite nodes with _f <= cost of optimal solution_)
	- Exponential time
	- Exponential space
	- Optimal

####IDA*
- Iterative Deepening A* iterates on the _f-limit_
- Initial _f-limit_ is _h(initialState)_ (i.e., the estimate of the distance from initalState to goal)
- Iteration _i_ has _f-limit_ of the lowest _f-value_ that exceeded the _i-1_ th _f-limit_
- IDA* is optimal and uses only linear space
- But, since it does tree-search, it _usually_ cannot detect when it hits a state a second time (could lead to an exponential space blow-up)
- Also, like ID, IDA* repeatedly re-expands earlier parts of the search tree on each iteration
- if enough memory is available A* is usually better

####Heuristics
- The quality of the heuristic determines how much search is needed to find a solution, perfect heuristic means no search
- if for 2 admissible heuristics, $h_2(n) > h_1(n)$ for all non-goal _n_. Then $h_2$ __dominates__ $h_1$ and $h_2$ is "better" for search (i.e., cannot expand more nodes)
- a heuristic is likely to be better than another when it's _average h-value_ is higher
- Comparing to uninformed:
	- Uninformed search tree size = $b^d$ where _b_ is the branching factor and _d_ is the length of the optimal solution
	- informed search tree size =  $b^(d-r)$ where _r_ is the _average heuristic_ value
- Heuristics can be constructed from 'simpler' versions of the problem
	- approximations
	- reformulations
	- abstractions
		- reduce the restrictions -> __relaxed problem__
	- decompositions
- Usually a trade-off between accuracy and cost to compute the heuristic

####Weighted A*
- Using an _admissible_ heuristic ensures that (ID)A* are optimal, but at the cost of exploring every node that could _potentially_ lead to a better solution
- Given an admissible heuristic _h_ we can derive a _possibly non-admissible_ heuristic by multiplying it with a weighting factor _w_
- $f(n) = g(n) + w * h(n), 0 <= w$
- We can guarantee that the solution ound cannot be worse than _w_ times as costly as the optimal solution
	- in reality, we may get a solution that is much better then the worst case

####Anytime search
- Start with a very large weight, and if we still have time, we can reduce the weight and potentially find a better solution

####Negation in prolog 
- In prolog something is _false_ if it cannot be proved true
- That is, if it cannot find a fact or rule that proves it true

####Bidirectional search
- a 1968 paper proved that A* was optimally efficient
	- i.e. using the same optimal heuristic no search could find the optimal path expanding fewer nodes
- however, we developed new algorithms to counter that space requirement (IDA*) and the exponential time requirement (trade optimality for speed)
- because the search space is exponential $(b^d -1)/(b-1)$, if we search from the initial state and backwards from the goal our space requirement is $2*( (b^(d/2) -1 )/(b-1) )$
- wave front collision detection
	- if complete states are represented then can be done by hashing states
	- if partial states are represented then we need some form of partial state matching
		- this eliminates all the savings derived from halving the exponent
- heuristics
	- if none are used then when the wave fronts collide we have found the optimal path
	- if heuristics are used then we can have found a much worse solution
		- e.g., they could form a circle where both wave fronts take a different path
- __Front-to-back__
	- _h(n)_ estimates the distance from _n_ to the opposite terminal (goal or init)
	- lack of coordination between frontiers
	- work like A* but more complicated
	- keeps searching until optimal solution found
- __Front-to-front__
	- _h(n)_ estimates the distance from _n_ to the opposite frontier (wave front)
	- frontiers are guided to each other
	- first collision is guaranteed optimal
	- since frontiers grow exponentially, the cost of computing _h_ grows exponentially
- which side to expand?
	- _cardinality criterion_ alternate each node
	- _f-levelling_ alternate at changes in f-value
	- _perimeter search_ grow one side to a perimeter then swap (only one swap)

####Constraint Satisfaction Problems (CSP)
- _state_ is defined by __variables__ $x_i$ with _values_ from __domain__ $D_i$
	- Discrete variables
		- finite domains (_n_ variables)
		- infinite domains (integers, strings, etc)
	- Continuous variables (time)
- _goal test_ is a set of __constraints__ specifying allowable combinations of values for subsets of variables
	- __Unary__ constraints involve a single variable (_SA != green_)
	- __Binary__ constraints involve variable pairs (_SA != WA_)
	- __Higher-order__ 3 or more varibles 
		- eg. cryptarithmetic column constrains
			- _TWO + TWO = FOUR_ ... _O + O = R + 10_ etc
- e.g. map coloring
	- variables: _WA, NT, Q, NSW, V, SA, T_
	- domains: _Di = {red, green, blue}_
	- constraints: adjacent regions must have different colors
- _constraint graph_ nodes are variables, arcs are constraints
- real world CSPs -- scheduling, timetables, assignment etc
- __incremental__ search
	- _initial state_ empty set
	- _successor function_ assign values to variables that do not confilct with current assignment
- __backtracking__ search (DFS)
	- assignments are _commutative_
	- choose the most contsrained variable ie. with the fewest legal values
		- _minimum remaining values (MRV)_ heuristic
		- tie breakers
			- choose varible with the most constraints on _remaining_ variables
			- choose the _value_ that rules out the frwest values in the remaining variables
	- __forward checking__
		- keep track of remaining legal values for variables
		- if a varible has no legal values then terminate the search
	- __arc consistency__
		- checks that for every value _x_ of _X_, there is _some_ allowed _y_
		- if one varible loses an available value, then it's neighbours must be checked
		- detects failure earlier than forward checking

------

##Pat Riddle
Lectures 13 onward

####Local Search
- __Hill climbing__ algorithm
	- like climbing Everest in fog
	- always moves toward a maxima
		- can get stuck on a local maxima -- missing the global maximum
	- add _random-restarts_ when you get stuck
		- trivially complete
	- depends very much on the shape of the state-space landscape
- __Simulated annealing__ search
	- allows some 'bad' moves to escape local maxima, but _gradually decreases_ their size and frequency
- __Local beam__ search
	- start with _k_ randomly generated states
	- pick the best
	- better than random restarts as information is shared -- but can get concentrated in a small region
- __Stochastic beam__ search
	- choose _k_ successors randomly, biased towards good ones (natural selection)


####Evolutionary Algorithms
- Necessary conditions:
	- An entity has the ability to _reproduce_ itself
	- there is a _population_ of such entities
	- there is some _variety_ among the entities
	- some _difference in ability to survive_ in the environment is associated with the variety
- __Genetic algorithms__
	- _search_ algorithms inspired by evolutionary processes
	- _highly parallel mathematical_ algorithms
	- transform a set (population) into a new population
	- each individual is associated with a _fitness value_ which plays a significant role in the transformation process
		- individuals reproduce with a _probability proportional to their fitness_
	- the closer two genes are, the more likely they will be passed onto the tame child
	- __overcrowding__ can happen if one individual is too dominant
- __Seeding algorithm__


####Min-Max search
- Perfect play for deterministic games
- Idea: choose move to position with highest __minimax value__
- Complete (if tree is finite)
- Optimal against an optimal opponent
- Time $O(b^m)$
- Space $O(b*m)$
- __alpha-beta pruning__
	- Does not affect the final result
	- With 'perfect ordering', time complexity $O(b^(m/2))$
		- _doubles_ depth of search which can be done in the same time
- __Cutoff test__
	- eg. depth limit, perhaps add _quiescence search_
- __Evaluation function__
	- estimated desirability of position
	- eg. for chess, typically _linear_ weighted sum of _features_
- __Monte Carlo Tree Search__
	- randomly plays out the rest of a game (thousands of times) and picks the move with the highest win percentage
	- uses upper confidence bound formula
		- explores the whole space
		- plays more under moves it wins
